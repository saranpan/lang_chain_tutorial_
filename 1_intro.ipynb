{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1b89b62a-00be-43a5-8855-43e20102be7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup environ\n",
    "import os \n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a806476-a38b-4553-9496-0fba43728647",
   "metadata": {},
   "source": [
    "# Initialize LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0cbfc00e-c4d8-4cca-93de-c13acd0b21fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "\n",
    "# Initialize LLM (From openai in this case)\n",
    "llm = OpenAI(temperature = 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3a9a584-c2a2-48d1-be57-9779187bf933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. Bangkok – the vibrant capital of Thailand, filled with culture, nightlife, and world-renowned street food.\n",
      "\n",
      "2. Chiang Mai – home to ancient temples, surrounded by lush nature, and a great spot for trekking.\n",
      "\n",
      "3. Phuket – a tropical paradise with stunning beaches, coral reefs and lively nightlife.\n",
      "\n",
      "4. Krabi – a coastal region of limestone cliffs, emerald waters, and beautiful caves.\n",
      "\n",
      "5. Koh Samui – an idyllic island with a stunning coastline, luxurious resorts and quirky nightlife.\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "\n",
    "text = \"What are the first 5 places to travel in Thailand\"\n",
    "output = llm(text)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2010a8-b739-45ee-b68d-32828c430ec9",
   "metadata": {},
   "source": [
    "# Prompt Template\n",
    "\n",
    "- offered by langchain, in case the prompt is a variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "447d8477-7ceb-48f1-8501-4dbe383d716f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables = ['country'],\n",
    "    template = 'What are the first 5 places to travel in {country}'\n",
    "                       )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362329a2-eeca-4c9f-a009-e03f009a30bb",
   "metadata": {
    "tags": []
   },
   "source": [
    "Here's the arguments of PromptTemplate\n",
    "\n",
    "<fieldset>\n",
    "input_variables: List[str] : \"\"\"A list of the names of the variables the prompt template expects.\"\"\"\n",
    "\n",
    "template: str\n",
    "\"\"\"The prompt template.\"\"\"\n",
    "\n",
    "template_format: str = \"f-string\"\n",
    "\"\"\"The format of the prompt template. Options are: 'f-string', 'jinja2'.\"\"\"\n",
    "\n",
    "validate_template: bool = True\n",
    "\"\"\"Whether or not to try validating the template.\"\"\"\n",
    "    </fieldset>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9a5d1ba-ada2-4ac0-979e-05daeb9604ac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text : What are the first 5 places to travel in England\n",
      "output : \n",
      "\n",
      "1. London\n",
      "2. Oxford\n",
      "3. Bath\n",
      "4. Norfolk\n",
      "5. The Cotswolds\n"
     ]
    }
   ],
   "source": [
    "text = prompt.format(country='England')\n",
    "print('text : ' + text)\n",
    "output = llm(text)\n",
    "print('output : ' + output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1fa09c8-7bb2-43c6-bed0-75fd71d4487b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Tools <- Agent -> LM\n",
    "\n",
    "- Once the agent got prompt, they will split the prompt into chunks (chains) if there are multiple questions in 1 prompt, and figure out how to implement tool per chain. Note that the one who decided to break chain and tools to use is under LM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "48f69830-8d2c-4ce7-8057-548fa77ceeb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ['SERPAPI_API_KEY']\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.agents import load_tools\n",
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bd2f8687-b41a-418e-8faf-037718258385",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0.0)\n",
    "tools = load_tools(['serpapi','llm-math'], llm=llm)\n",
    "agents = initialize_agent(tools, llm, agent='zero-shot-react-description',verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8678d1aa-551f-41cd-b4a3-bb61531ac846",
   "metadata": {},
   "source": [
    "- The reason why we need llm as arguments is because of llm-math (it depends on the type of llm)\n",
    "- Without llm-math, the llm argument llm is not required\n",
    "- verbose=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8dbf07ca-67e4-47c9-9c7e-3c02d95d6359",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to find out who the current prime minister is, how long he has been in office, and who is expected to be the next prime minister\n",
      "Action: Search\n",
      "Action Input: \"Current prime minister of Thailand\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mPrayut Chan-o-cha\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to find out how long he has been in office\n",
      "Action: Search\n",
      "Action Input: \"Prayut Chan-o-cha prime minister of Thailand\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mPrayut Chan-o-cha is a Thai politician and retired army officer who has served as the Prime Minister of Thailand since he seized power in a military coup in 2014. He is concurrently the Minister of Defence, a position he has held in his own government since 2019.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to find out who is expected to be the next prime minister\n",
      "Action: Search\n",
      "Action Input: \"Next expected prime minister of Thailand\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mVoting is set for Sunday, with progressive parties calling for reforms to the monarchy and military.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: Prayut Chan-o-cha has been the Prime Minister of Thailand since 2014 and is expected to remain in office until the next election, which is set for Sunday.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Prayut Chan-o-cha has been the Prime Minister of Thailand since 2014 and is expected to remain in office until the next election, which is set for Sunday.'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'Who is the current prime minister of Thailand, and how long he stayed as prime minister, and what is the next expected prime minister'\n",
    "agents.run(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d96404-e5b2-44fe-9e53-f6dffa96b368",
   "metadata": {},
   "source": [
    "# Memory : Add state to agents and chains\n",
    "\n",
    "The previous agent does not memorize? It is decided for a series of user prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f5af660e-fd64-4ba2-bec9-08a8a7bc0efd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Another type of agents which decided to memorize the previous prompt\n",
    "from langchain import ConversationChain\n",
    "llm = OpenAI(temperature=0.0)\n",
    "conversation = ConversationChain(llm=llm,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8ee6e33f-fc3a-418a-842e-500c2f28a73e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hello, I love eating salad\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" Hi there! That's great to hear. I'm an AI, so I don't eat food, but I do love learning about different types of food. What kind of salad do you like to eat?\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input='Hello, I love eating salad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ac8439e6-b795-4da5-b551-db3bf463fd65",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hello, I love eating salad\n",
      "AI:  Hi there! That's great to hear. I'm an AI, so I don't eat food, but I do love learning about different types of food. What kind of salad do you like to eat?\n",
      "Human: Salad with mushroom\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Interesting! Mushrooms are a great addition to salads. Do you like to add any other ingredients to your salads?'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input='Salad with mushroom')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8fb1126e-2cb6-4b88-b93e-24cf89123d04",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hello, I love eating salad\n",
      "AI:  Hi there! That's great to hear. I'm an AI, so I don't eat food, but I do love learning about different types of food. What kind of salad do you like to eat?\n",
      "Human: Salad with mushroom\n",
      "AI:  Interesting! Mushrooms are a great addition to salads. Do you like to add any other ingredients to your salads?\n",
      "Human: Do you think I love eating meat or vegetarian\n",
      "AI:  I'm not sure. It's hard to say without knowing more about your preferences. Do you usually eat meat or vegetarian dishes?\n",
      "Human: What did I say at the first time\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'  At the first time, you said that you love eating salad.'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input='What did I say at the first time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42713190-4641-4743-9b48-8ec860ebcba1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:oic_langchain]",
   "language": "python",
   "name": "conda-env-oic_langchain-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
