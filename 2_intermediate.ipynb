{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "163148aa-5302-4355-ad93-8d3193ad1354",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup environ\n",
    "import os \n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1393c7a4-31ac-4e6e-ac66-55f3f27bbcca",
   "metadata": {},
   "source": [
    "# Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a0af03-747d-433b-afbc-b1ac2776f9ba",
   "metadata": {},
   "source": [
    "ref : https://docs.langchain.com/docs/category/components"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8098989d-de3d-46d5-ae4a-31e4c47b7b88",
   "metadata": {},
   "source": [
    "- Recall that Langchain comprises of 7 main components"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f31634-eed0-44c9-8e8e-6870564a2567",
   "metadata": {
    "tags": []
   },
   "source": [
    "![](asset/lang_components.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb787710-6243-4a23-a099-89a4f6818560",
   "metadata": {},
   "source": [
    "# Why LM alone is not enough\n",
    "\n",
    "1. Data-aware: connect a language model to other sources of data\n",
    "\n",
    "2. Agentic: allow a language model to interact with its environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e2cd12-e778-4422-90a8-bffad95bbefe",
   "metadata": {},
   "source": [
    "# 1. Schema\n",
    "\n",
    "- The representation of theory you use to communicate with agent\n",
    "- The structure of the prompt\n",
    "- Langchain represent each type in form of object\n",
    "\n",
    "There are 4 main types of that representation\n",
    "\n",
    "## 1.1. Text\n",
    "\n",
    "> Just a straightforward text prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20e067db-33f2-44bf-8eee-7b181b9a653a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "If you love eating chocolate, you should go to a chocolate store, such as Godiva, Ghirardelli, Lindt, or Hershey's.\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "llm = OpenAI(temperature=0.0)\n",
    "\n",
    "text = \"If I love eating chocolate, which store name I need to go\"\n",
    "output = llm(text)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecad6d37-f85a-4983-a834-75c26b60f030",
   "metadata": {},
   "source": [
    "## 1.2. ChatMessage\n",
    "\n",
    "> The idea behind this is to keep the memory of the previous state\n",
    "\n",
    "> Langchain offers a better way instead of prompt like\n",
    "\n",
    "\"\"\"\n",
    "Instruction : You are the nutritionist who dedicated to help the people that lack of nutrition <br>\n",
    "\n",
    "Here's the example <br>\n",
    "\n",
    "User : I am flu, what should I eat<br>\n",
    "AI : Try eating fruits with a rich of vitamin C<br>\n",
    "User : {Input}<br>\n",
    "AI : {Output}<br>\n",
    "\"\"\"\n",
    "\n",
    "> It comprises of 3 main components : \n",
    "\n",
    "- SystemChatMessage - Instruct the AI\n",
    "- HumanMessage - What the user want to prompt\n",
    "- AiMessage - What the Ai will prompt out  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c1861a0-3027-47e5-9973-7137424e4600",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "# These 3 are Chat schema\n",
    "from langchain.schema import HumanMessage, SystemMessage, AIMessage\n",
    "\n",
    "# Model type : Chat Models\n",
    "chat = ChatOpenAI(temperature = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47339678-db0f-44ce-8cdf-7f627f02f0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is how we represent the prompt more structurally\n",
    "chat_history = [\n",
    "                SystemMessage(content=\"You are the nutritionist who dedicated to help the people that lack of nutrition\"),\n",
    "                HumanMessage(content=\"I am flu, what should I eat\"),\n",
    "                AIMessage(content=\"Try eating fruits with a rich of vitamin C\"),\n",
    "                HumanMessage(content=\"Which fruits are those\")             \n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "785b625c-0865-493c-823a-1df7faa1ac59",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Some fruits that are rich in vitamin C include oranges, grapefruits, kiwis, strawberries, papayas, and pineapples. These fruits can help boost your immune system and fight off the flu. Additionally, you can also try drinking warm liquids like tea or soup to help soothe your throat and alleviate congestion.', additional_kwargs={}, example=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat(chat_history)\n",
    "\n",
    "# You can see the AIMessage come here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d09bc3ad-2419-4377-9670-6745c7855b9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Another example\n",
    "# Here is how we represent the prompt more structurally\n",
    "chat_history = [\n",
    "                SystemMessage(content=\"You are a doctor intern who learn to investigate a patient\"),\n",
    "                AIMessage(content=\"Okay, how are you\"),\n",
    "                HumanMessage(content=\"I sneeze every 5 minutes\")          \n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6b5f0eef-d877-436a-9b9e-a9ac3c7a4522",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Okay, let's start by asking a few questions to better understand your symptoms. \\n\\n1. How long have you been experiencing these symptoms? \\n2. Do you have any other symptoms such as a runny nose, itchy or watery eyes, or a sore throat? \\n3. Have you been exposed to any allergens or irritants recently? \\n4. Have you recently started taking any new medications or supplements? \\n5. Have you had any recent changes in your environment or lifestyle? \\n\\nBased on your answers, I may recommend further testing or refer you to a specialist for further evaluation.\", additional_kwargs={}, example=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat(chat_history)\n",
    "\n",
    "# You can see the AIMessage come here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd357ec-5436-4cac-af34-83970e798f3a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1.3. Document\n",
    "\n",
    "- So, the objective is to tell the document to use and its metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5b6d536d-c3ea-47fb-a386-0124cb4060da",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imported successfully\n"
     ]
    }
   ],
   "source": [
    "from langchain.schema import Document\n",
    "import requests\n",
    "\n",
    "document_url = 'https://icrrd.com/media/16-05-2021-080425Why-We-Sleep-Unlocking-the-Power-of-Sleep.pdf'\n",
    "document_dest = 'source/why_we_sleep.pdf'\n",
    "\n",
    "document = requests.get(document_url)\n",
    "with open(document_dest, 'wb') as f:\n",
    "    f.write(document.content)\n",
    "\n",
    "print('imported successfully')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53054169-d65a-4fbe-b574-6ddba2ccdcc8",
   "metadata": {},
   "source": [
    "Sepcifically, it is used for filtering the specific documents in your database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e7a67ee0-951a-4cbf-b5a6-7b4aa958f8e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='This is a book about sleepinp', metadata={'book_name': 'Why we sleep by Matthew Walker', 'book_source': 'source/why_we_sleep.pdf', 'book_timestamp': '11/10/2022'})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Document(page_content= \"This is a book about sleepinp\",\n",
    "        metadata={\"book_name\" : \"Why we sleep by Matthew Walker\",\n",
    "                 \"book_source\" : document_dest,\n",
    "                 \"book_timestamp\" : \"11/10/2022\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3075511-b233-4709-82e2-b95cfd3448fd",
   "metadata": {},
   "source": [
    "## 1.4. Example\n",
    "\n",
    "- The idea of N-shot prompt "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd48824-a04e-4962-903d-2b5582492294",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 2. Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1fb329d-f594-4166-b604-16b3e695316d",
   "metadata": {},
   "source": [
    "## 2.1. LLMs\n",
    "\n",
    "- text as an input and returns text as an output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "330d21aa-2b77-4efe-a9f7-8fa026a89b29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# % Already saw it\n",
    "\n",
    "from langchain.llms import OpenAI\n",
    "llm = OpenAI(temperature=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900299a4-077a-4666-9b4e-65297cfeb964",
   "metadata": {},
   "source": [
    "## 2.2. Chat models\n",
    "\n",
    "- a list of ChatMessages as an input and returns a ChatMessage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2feafa31-dd91-4659-9ffc-ce671e52180e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# Model type : Chat Models\n",
    "chat = ChatOpenAI(temperature = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fdb176f-94f3-4fa7-9dea-ce11ce27fbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The prompt for chat model can be the chat_history we shown before"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c616c19-dc53-4841-9e8e-e3aadd5a2a35",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2.3. Text Embedding Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b720892-fd4f-4b80-b3cc-5ca539e68e66",
   "metadata": {},
   "source": [
    "OpenAI’s text embeddings measure the relatedness of text strings. Embeddings are commonly used for:\n",
    "\n",
    "- Search (where results are ranked by relevance to a query string)\n",
    "- Clustering (where text strings are grouped by similarity)\n",
    "- Recommendations (where items with related text strings are recommended)\n",
    "- Anomaly detection (where outliers with little relatedness are identified)\n",
    "- Diversity measurement (where similarity distributions are analyzed)\n",
    "- Classification (where text strings are classified by their most similar label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ae51197-4f44-4ef1-b8ab-783240fe9bef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "699f5d39-2a56-49b5-8345-3c627998349e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1536\n",
      "[0.007248167414218187, -0.014703948982059956, -0.0025203716941177845, -0.0057032760232687, -0.026012800633907318]\n"
     ]
    }
   ],
   "source": [
    "txt_embedding = embeddings.embed_query(\"I love eating food\") # Vector\n",
    "\n",
    "print(len(txt_embedding))\n",
    "print(txt_embedding[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0badf3-c784-46ee-b631-ffb3eb6756b1",
   "metadata": {},
   "source": [
    "These are the embedding vector for the query \"I love eating food\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeefe981-5030-411b-86e4-b722300f6913",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 3. Prompt\n",
    "\n",
    "- PromptValue\n",
    "\n",
    "> The class representing an input to a model.\n",
    "\n",
    "- Prompt Templates\n",
    "\n",
    "> The class in charge of constructing a PromptValue.\n",
    "\n",
    "- Example Selectors\n",
    "\n",
    "> Often times it is useful to include examples in prompts. These examples can be hardcoded, but it is often more powerful if they are dynamically selected.\n",
    "\n",
    "- Output Parsers\n",
    "\n",
    "> Language models (and Chat Models) output text. But many times you may want to get more structured information than just text back. This is where output parsers come in. Output Parsers are responsible for (1) instructing the model how output should be formatted, (2) parsing output into the desired formatting (including retrying if necessary)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24c65fc-bf83-49aa-b870-d859c28c904d",
   "metadata": {},
   "source": [
    "## 3.1. Prompt value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "efa2c876-9aa6-4a19-b28f-320f4e808408",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "I luv eating raw chicken\n",
    "\n",
    "What's wrong with that\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b4d451-5861-4886-b09c-1d9d1416f094",
   "metadata": {},
   "source": [
    "## 3.2. Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "63a11a4a-d7e4-4bdc-9faf-65f7ad430531",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['food'] output_parser=None partial_variables={} template=\"\\n\\nI really love {food}\\n\\nWhat's wrong with that \\n\" template_format='f-string' validate_template=True\n",
      "\n",
      "\n",
      "I really love raw chicken\n",
      "\n",
      "What's wrong with that \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain import OpenAI\n",
    "from langchain import PromptTemplate\n",
    "\n",
    "template = \"\"\"\n",
    "\n",
    "I really love {food}\n",
    "\n",
    "What's wrong with that \n",
    "\"\"\"\n",
    "\n",
    "# Declare the prompt template, and define the input var\n",
    "prompt_template = PromptTemplate(input_variables = [\"food\"], template = template)\n",
    "print(prompt_template)\n",
    "# Demonstrate how to derive the final prompt\n",
    "final_prompt = prompt_template.format(food = 'raw chicken')\n",
    "print(final_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d048419a-60ad-4402-af69-a5339c5712e5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nRaw chicken can contain harmful bacteria, such as salmonella, that can make you very sick if it is not cooked properly. It is important to always cook chicken thoroughly to an internal temperature of 165°F to ensure that any bacteria present is killed.'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = OpenAI(temperature=0)\n",
    "llm(final_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b276dd1-9952-460a-9a6a-9e7ac6d3b5a2",
   "metadata": {},
   "source": [
    "## 3.3. Example Selectors\n",
    "\n",
    "- Make the example (few shot learning) more relevant to the question example \n",
    "- In real world, we have a ton of examples, but the prompt cannot exceed the limit token, so to reduce the token, instead of showing them all examples, we pick the more appropriate example related to the question\n",
    "\n",
    "Eg. \n",
    "\n",
    "```\n",
    "Give the Location of an item usually found in\n",
    "\n",
    "Example Input : driver\n",
    "Example Output : car\n",
    "\n",
    "Example Input : pilot\n",
    "Example Output : plane\n",
    "\n",
    "Input : student\n",
    "Output : \n",
    "```\n",
    "\n",
    "\n",
    "```\n",
    "Give the Location of an item usually found in\n",
    "\n",
    "Example Input : tree\n",
    "Example Output : ground\n",
    "\n",
    "Example Input : bird\n",
    "Example Output : nest\n",
    "\n",
    "Input : flower\n",
    "Output : \n",
    "```\n",
    "\n",
    "See the example is changed due to the input, the agent will try their best to pick the best example related to input\n",
    "\n",
    "If the input prompt is flower, then the example pair that make the LLM do their best is \n",
    "\n",
    "(tree,ground), (bird,nest)\n",
    "\n",
    "The reason behind this might be because (tree & flower) and (bird & flower) are closer than (driver & flower) and (pilot & flower)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf95c58-130a-4361-887a-2ebcea27a4e8",
   "metadata": {},
   "source": [
    "Choosing the right index which is the most similar to the query,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fdacd4ad-fbef-4fe1-b4e3-c2d38fa46f43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This will engineer the prompt first before entering to LLM\n",
    "# Using the prompt template\n",
    "# But the example is selected based on ...\n",
    "\n",
    "from langchain import PromptTemplate\n",
    "from langchain.prompts.example_selector import SemanticSimilarityExampleSelector\n",
    "from langchain.vectorstores import FAISS  # FAISS : lib that choose the right index which is the most similar to the query with the v. hgh speed\n",
    "\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables = [\"input\",\"output\"],\n",
    "    template = \"Example Input : {input}, Example Output : {output}\")\n",
    "\n",
    "# Examples of locations that nouns are found\n",
    "examples = [\n",
    "    {\"input\": \"pirate\", \"output\": \"ship\"}, # This is the str format for example_prompt\n",
    "    {\"input\": \"pilot\", \"output\": \"plane\"}, \n",
    "    {\"input\": \"driver\", \"output\": \"car\"},\n",
    "    {\"input\": \"tree\", \"output\": \"ground\"},\n",
    "    {\"input\": \"bird\", \"output\": \"nest\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cb72d4c0-678e-4050-b31b-3f1d9bed77a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# There are 3 main things required here to select\n",
    "#1.examples pair (examples)\n",
    "#2.embedding function (OPENAI embedding)\n",
    "#3.algorithm to output the index (FAISS) (imagine a billion vector, and have to sort the top 3 vector with highest similarity)\n",
    "\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "# Select the \n",
    "example_selector = SemanticSimilarityExampleSelector.from_examples(\n",
    "    examples, # This is the list of examples available to select from. \n",
    "    OpenAIEmbeddings(),  # This is the embedding class used to produce embeddings which are used to measure semantic similarity.\n",
    "    FAISS, # This is the VectorStore class that is used to store the embeddings and do a similarity search over.\n",
    "    k=2 # This is the number of examples to produce.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c513a7e7-4a05-48a3-ac59-f999026103be",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SemanticSimilarityExampleSelector(vectorstore=<langchain.vectorstores.faiss.FAISS object at 0x16b146430>, k=2, example_keys=None, input_keys=None)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1b60e917-54e9-4b8f-a4a5-f05452570ea9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FewShotPromptTemplate(input_variables=['noun'], output_parser=None, partial_variables={}, examples=None, example_selector=SemanticSimilarityExampleSelector(vectorstore=<langchain.vectorstores.faiss.FAISS object at 0x16b146430>, k=2, example_keys=None, input_keys=None), example_prompt=PromptTemplate(input_variables=['input', 'output'], output_parser=None, partial_variables={}, template='Example Input : {input}, Example Output : {output}', template_format='f-string', validate_template=True), suffix='Input: {noun}\\nOutput:', example_separator='\\n\\n', prefix='Give the location an item is usually found in', template_format='f-string', validate_template=True)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import FewShotPromptTemplate\n",
    "#### Structure of few-shot-prompt #####\n",
    "            # Instruction #\n",
    "            # Example #\n",
    "            # Question #\n",
    "\n",
    "similar_prompt = FewShotPromptTemplate(\n",
    "    example_selector=example_selector, # The object that will help select examples # \n",
    "    example_prompt=example_prompt,\n",
    "    prefix=\"Give the location an item is usually found in\",# Customizations that will be added to the top\n",
    "    suffix=\"Input: {noun}\\nOutput:\", # and bottom of your prompt\n",
    "    input_variables=[\"noun\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c15b0ffd-7f66-4547-8d75-932a28f253ad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Give the location an item is usually found in\n",
      "\n",
      "Example Input : driver, Example Output : car\n",
      "\n",
      "Example Input : pilot, Example Output : plane\n",
      "\n",
      "Input: student\n",
      "Output:\n"
     ]
    }
   ],
   "source": [
    "# You can see the example is varied\n",
    "my_noun = \"student\"\n",
    "final_prompt = similar_prompt.format(noun=my_noun)\n",
    "print(final_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "49325a9c-a472-4d4e-b374-49f989633725",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' classroom'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's input the final prompt\n",
    "llm(final_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21bc3ca0-7744-41b1-9c24-fa8401c7e2fd",
   "metadata": {},
   "source": [
    "# 3.4. Output Parser\n",
    "\n",
    "- Want the output from the model to be JSON, or any strutural format, rather than string ? \n",
    "- langchain know how to prompt llm to make the output be in the desirable format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6cb35b29-8c1d-48d7-a6bb-19c23b710341",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The idea is the langchain will find the best {format} instruction for you\n",
    "\n",
    "template = \"\"\"\n",
    "        You will be given a poorly formatted string from a user.\n",
    "        Reformat it and make sure all the words are spelled correctly\n",
    "\n",
    "        {format_instructions}\n",
    "\n",
    "        % USER INPUT:\n",
    "        {user_input}\n",
    "\n",
    "        YOUR RESPONSE:\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cccb9ffa-c4a7-40a4-8dec-9123b0a52d2f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
    "\n",
    "# How you would like your response structured. This is basically a fancy prompt template\n",
    "response_schemas = [\n",
    "    ResponseSchema(name=\"bad_string\", description=\"This a poorly formatted user input string\"),\n",
    "    ResponseSchema(name=\"good_string\", description=\"This is your response, a reformatted response\")\n",
    "]\n",
    "\n",
    "# How you would like to parse your output\n",
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "32ffdd93-04be-46f1-b87f-1ced7f43be2d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"\\`\\`\\`json\" and \"\\`\\`\\`\":\n",
      "\n",
      "```json\n",
      "{\n",
      "\t\"bad_string\": string  // This a poorly formatted user input string\n",
      "\t\"good_string\": string  // This is your response, a reformatted response\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# Print the output format\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "print (format_instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0abca17d-fe11-486b-91e5-5858f4a2974b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You will be given a poorly formatted string from a user.\n",
      "Reformat it and make sure all the words are spelled correctly\n",
      "\n",
      "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"\\`\\`\\`json\" and \"\\`\\`\\`\":\n",
      "\n",
      "```json\n",
      "{\n",
      "\t\"bad_string\": string  // This a poorly formatted user input string\n",
      "\t\"good_string\": string  // This is your response, a reformatted response\n",
      "}\n",
      "```\n",
      "\n",
      "% USER INPUT:\n",
      "i iove u\n",
      "\n",
      "YOUR RESPONSE:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"user_input\"],\n",
    "    partial_variables={\"format_instructions\": format_instructions},\n",
    "    template=template\n",
    ")\n",
    "\n",
    "final_prompt = prompt.format(user_input = \"i iove u\")\n",
    "print(final_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7d72cbc6-b26b-434c-83f2-48169d291267",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "\t\"bad_string\": \"i iove u\",\n",
      "\t\"good_string\": \"I love you\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "output = llm(final_prompt)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b423c7a0-52af-482a-8622-c1e40868ba4e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bad_string': 'i iove u', 'good_string': 'I love you'}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Turn to json\n",
    "output_parser.parse(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264f4dd8-df88-4206-a725-7cc7e164ccfb",
   "metadata": {},
   "source": [
    "# 4. Indexs \n",
    "\n",
    "- Indexes refer to ways to structure documents so that LLMs can best interact with them\n",
    "- It is impossible to input whole document to your LLM\n",
    "- One possible technique they did is split the document into many documents by chunk size\n",
    "- say your document has 10000 tokens, it an be splitted into 10, if you determine the chunk size as 1000\n",
    "- and iteratively input those document to LLM\n",
    "- However, this technique might not be common, because the LLM has to memorize and get distorted by irrelevant document\n",
    "- So, instead of input all documents, we better input just the most relevant documents based on the user query that indexes which is called \"retrieval\" step. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f19dad3-4c02-4401-93b1-ff2d9d402982",
   "metadata": {},
   "source": [
    "![](asset/index_langchain.png)\n",
    "ref : https://www.youtube.com/watch?v=RIWbalZ7sTo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3227eb9c-0cf4-452f-ac03-40040ede4682",
   "metadata": {},
   "source": [
    "## 4.1. Document Loader\n",
    "\n",
    "- Without this, how can you download the document. well, maybe use f.read(..)\n",
    "- However, langchain offers us the better ways, since this Loader can interact with the rest of pipeline from langchain better\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a5ec9d76-b54b-481d-a402-0bb038aab591",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "document_dest = 'source/why_we_sleep.pdf'\n",
    "\n",
    "loader = PyPDFLoader(document_dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db7556d-8d02-48e1-ae12-3391f7c92e6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "documents = loader.load() # loader.load_and_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "d1d61e81-f711-4cd0-8e17-0b3504e31421",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This pdf contains 372 pages\n"
     ]
    }
   ],
   "source": [
    "print(f\"This pdf contains {len(documents)} pages\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ddf8833-0a31-4ef5-b833-bbfa888f2fe7",
   "metadata": {},
   "source": [
    "## 4.2. Text splitter\n",
    "\n",
    "- This is the part where we turn document into chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "bf9cc902-d9e2-4d3a-baab-695047be5ce9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS \n",
    "\n",
    "# Size is count by character not token\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000,chunk_overlap=50)\n",
    "\n",
    "texts = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "25bdccb4-2f31-455d-aed7-bd4b5f6441df",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of documents (splitted) :  993\n"
     ]
    }
   ],
   "source": [
    "print('number of documents (splitted) : ', len(texts))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2b833f-ecb2-4187-b133-62a5ab18edfe",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 4.3. VectorStores\n",
    "\n",
    "- Where can we store the embedding of the spllited document\n",
    "- Here it is, if you have 993 documents, then 993 embedding vector were created and store in here\n",
    "- We adopted FAISS which was vectorstore developed by Meta\n",
    "- Its greatness is not only offering the place to store, but also how they quickly return the most relevant embedding vector regard of the query\n",
    "- They find the index of the most relevant embedding vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "460c6b97-905c-4a49-8fc9-4fd7db37969f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We will use this function to emb each splitted document\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "# Embed and store in this\n",
    "db = FAISS.from_documents(texts,embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1209248-12c5-45ae-b2ab-15109f46f21e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 4.4. Retrieval\n",
    "\n",
    "- Every vectorstore have its own retrieval utility function \n",
    "- The goal here is to return the index of (splitted) document which has the highest similarity to the user query, so they can return the document that most relevant to query\n",
    "- The top K documents is arbitrary, you may need to obtain top 1 or 5 documents regarding to query using search_kwarg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "6f0f07d5-bba7-4ad3-a0b1-b3f1a82debf8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Declare retriever object from database\n",
    "# Get the top 5 documents\n",
    "\n",
    "search_kwargs=dict(k=5)\n",
    "retriever = db.as_retriever(search_kwargs = search_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "da36803d-595a-4191-aaeb-7097b254d73d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(vectorstore=<langchain.vectorstores.faiss.FAISS object at 0x1254e8e50>, search_type='similarity', search_kwargs={'k': 5})"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "dec52e27-736f-43b8-b606-4803c043ddac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method get_relevant_documents in module langchain.vectorstores.base:\n",
      "\n",
      "get_relevant_documents(query: 'str') -> 'List[Document]' method of langchain.vectorstores.base.VectorStoreRetriever instance\n",
      "    Get documents relevant for a query.\n",
      "    \n",
      "    Args:\n",
      "        query: string to find relevant documents for\n",
      "    \n",
      "    Returns:\n",
      "        List of relevant documents\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(retriever.get_relevant_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "993f39bc-632e-44b2-9508-60242210ef5f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='the report by stating that the eﬀect of current sleeping medications was\\n“rather small and of questionable clinical importance.” Even the newest\\nsleeping pill for insomnia, called suvorexant (brand name Belsomra), has\\nproved minimally eﬀective, as we discussed in chapter 12. Future versions of\\nsuch drugs may oﬀer meaningful sleep improvements, but for now the\\nscientiﬁc data on prescription sleeping pills suggests that they may not be\\nthe answer to returning sound sleep to those struggling to generate it on\\ntheir own.\\nSLEEPING PILLS— THE BAD, THE BAD, AND THE UGLY\\nExisting prescription sleeping pills are minimally helpful, but are they\\nharmful, even deadly? Numerous studies have something to say on this\\npoint, yet much of the public remains unaware of their ﬁndings.\\nNatural deep sleep, as we have previously learned, helps cement new\\nmemory traces within the brain, part of which require the active\\nstrengthening of connections between synapses that make up a memory', metadata={'source': 'source/why_we_sleep.pdf', 'page': 273}),\n",
       " Document(page_content='CHAPTER 14\\nHurting and Helping Your Sleep\\nPills vs. \\ue061erapy\\nIn the past month, almost 10 million people in America will have swallowed\\nsome kind of a sleeping aid. Most relevant, and a key focus of this chapter, is\\nthe (ab)use of prescription sleeping pills. Sleeping pills do not provide natural\\nsleep, can damage health, and increase the risk of life-threatening diseases.\\nWe will explore the alternatives that exist for improving sleep and combating\\ninsipid insomnia.\\nSHOULD  YOU T AKE TWO OF THESE BEFORE BED?\\nNo past or current sleeping medications on the legal (or illegal) market\\ninduce natural sleep. Don’t get me wrong—no one would claim that you are\\nawake after taking prescription sleeping pills. But to suggest that you are\\nexperiencing natural sleep would be an equally false assertion.\\n\\ue033e older sleep medications—termed “sedative hypnotics,” such as\\ndiazepam—w ere blunt instruments. \\ue033ey sedated you rather than assisting', metadata={'source': 'source/why_we_sleep.pdf', 'page': 271}),\n",
       " Document(page_content='examined all published studies to date on newer forms of sedative sleeping\\npills that most people take.II \\ue033ey considered sixty-ﬁve separate drug-\\nplacebo studies, encompassing almost 4,500 individuals. Overall, participants\\nsubjectively felt they fell asleep faster and slept more soundly with fewer\\nawakenings, relative to the placebo. But that’s not what the actual sleep\\nrecordings showed. \\ue033ere was no diﬀerence in how soundly the individuals\\nslept. Both the placebo and the sleeping pills reduced the time it took people\\nto fall asleep (between ten and thirty minutes), but the change was not\\nstatistically diﬀerent between the two. In other words, there was no objective\\nbeneﬁt of these sleeping pills beyond that which a placebo oﬀered.\\nSummarizing the ﬁndings, the committee stated that sleeping pills only\\nproduced “slight improvements in subjective and polysomnographic sleep\\nlatency”—that is, the time it takes to fall asleep. \\ue033e committee concluded', metadata={'source': 'source/why_we_sleep.pdf', 'page': 273}),\n",
       " Document(page_content='the ﬁrst-line treatment for all individuals with chronic insomnia, not sleeping\\npills.VIII\\nYou can ﬁnd more resources on CBT-I, and a list of qualiﬁed therapists,\\nfrom the National Sleep Foundation’s website.IX If you have, or think you\\nhave, insomnia, please make use of these resources before turning to sleeping\\npills.\\nGENERAL GOOD  SLEEP PRACTICES\\nFor those of us who are not suﬀering from insomnia or another sleep\\ndisorder, there is much we can do to secure a far better night of sleep using\\nwhat we call good “sleep hygiene” practices, for which a list of twelve key tips\\ncan be found at the National Institutes of Health website; also oﬀered in the\\nappendix of this book.X All twelve suggestions are superb advice, but if you\\ncan only adhere to one of these each and every day, make it: going to bed and\\nwaking up at the same time of day no matter what. It is perhaps the single\\nmost eﬀective way of helping improve your sleep, even though it involves the\\nuse of an alarm clock.', metadata={'source': 'source/why_we_sleep.pdf', 'page': 280}),\n",
       " Document(page_content='having learned about this evidence?\\nTo be very clear, I am not anti-medication. On the contrary, I desperately\\nwant there to be a drug that helps people obtain truly naturalistic sleep.\\nMany of the drug company scientists who create sleeping medicines do so\\nwith nothing but good intent and an honest desire to help those for whom\\nsleep is problematic. I know, because I have met many of them in my career.\\nAnd as a researcher, I am keen to help science explore new medications in\\ncarefully controlled, independent studies. If such a drug—one with sound\\nscientiﬁc data demonstrating beneﬁts that far outweigh any health risks—is\\nultimately developed, I would support it. It is simply that no such medication\\ncurrently exists.\\nDON’T TAKE TWO OF T HESE, INSTEAD TRY THESE\\nWhile the search for more sophisticated sleep drugs continues, a new wave\\nof exciting, non-pharmacological methods for improving sleep are fast\\nemerging. Beyond the electrical, magnetic, and auditory stimulation', metadata={'source': 'source/why_we_sleep.pdf', 'page': 278})]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.get_relevant_documents('sleeping pill to help me sleep better',)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6fc288-965b-41e2-a7be-1f54e57196a5",
   "metadata": {},
   "source": [
    "# 5. Memory\n",
    "\n",
    "- Instead of directly prompt after instruction template, we can even tell openai what we chatted to this before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "aa0750aa-b9ce-4a03-ab1b-c6e69d61efaa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.memory import ChatMessageHistory\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "chat = ChatOpenAI(temperature=0)\n",
    "\n",
    "history = ChatMessageHistory()\n",
    "history.add_ai_message(\"Hi\")\n",
    "history.add_user_message(\"What is the capital of Thailand\")\n",
    "history.add_ai_message(\"It is Rome\")\n",
    "history.add_user_message(\"That's not true, I will give you one more chance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "0ee2d4fd-ac54-4841-95ff-471638b7a807",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIMessage(content='Hi', additional_kwargs={}, example=False),\n",
       " HumanMessage(content='What is the capital of Thailand', additional_kwargs={}, example=False),\n",
       " AIMessage(content='It is Rome', additional_kwargs={}, example=False),\n",
       " HumanMessage(content=\"That's not true, I will give you one more chance\", additional_kwargs={}, example=False)]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.messages\n",
    "# You can observe that the history simply store the Chat schema with AI message and User mesage on our first chapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "a1bf00fd-f3c4-4b27-acfd-7880ec8886ff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='I apologize for the mistake. The capital of Thailand is Bangkok.', additional_kwargs={}, example=False)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_response = chat(history.messages)\n",
    "ai_response # Just an AIMessage object, so w ecan append it to history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "791409fe-a946-4a68-9f89-14b3865942db",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='How may I assist you today?', additional_kwargs={}, example=False)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.add_ai_message(ai_response.content)\n",
    "ai_response = chat(history.messages)\n",
    "ai_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7df039-094c-4296-a027-6de1d495c456",
   "metadata": {},
   "source": [
    "# 6. Chains\n",
    "\n",
    "- It's how we break the question into a series of questions. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "e4fbbd38-3ac7-4ee2-a7af-ca05a036e2e5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'product': 'colorful socks', 'text': '\\n\\nSocktastic!'}"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Basic of chain (its input and output)\n",
    "# You can see the output is json\n",
    "from langchain import PromptTemplate, OpenAI, LLMChain\n",
    "\n",
    "prompt_template = \"What is a good name for a company that makes {product}?\"\n",
    "\n",
    "llm = OpenAI(temperature=0)\n",
    "llm_chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=PromptTemplate.from_template(prompt_template)\n",
    ")\n",
    "llm_chain(\"colorful socks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "50b66f12-31f1-49d8-9a69-8fbe43c6c63b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import SimpleSequentialChain\n",
    "\n",
    "llm = OpenAI(temperature=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43fb89ea-6f2c-4365-ab6a-e1c8f82c75d3",
   "metadata": {},
   "source": [
    "- Imagine you were asked to tell how to make the popular dish in Bangkok\n",
    "- The very first thing gyou need to do is to search which dish is\n",
    "- Then you will use that dish and find the ingredient and how to make that dish\n",
    "\n",
    "We can summarize as this\n",
    "\n",
    "input -> chain_1 -> output -> chain_2 -> output\n",
    "\n",
    "We will use the outout fromt he chain 1 as input of chain 2\n",
    "\n",
    "- In this case, we can use SimpleSequentialChain\n",
    "\n",
    "- Note that each chain is LLMchain object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "0b30c2b5-f2cf-4bf6-9d53-74b70cd174fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Chain 1\n",
    "\n",
    "template = \"\"\"Your job is to come up with a classic dish from the area that the users suggests.\n",
    "% USER LOCATION\n",
    "{user_location}\n",
    "\n",
    "YOUR RESPONSE:\n",
    "\"\"\"\n",
    "prompt_template = PromptTemplate(input_variables=[\"user_location\"], template=template)\n",
    "\n",
    "# Holds my 'location' chain\n",
    "location_chain = LLMChain(llm=llm, prompt=prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "6d826243-cdaf-4e38-94dc-45a4e3298f51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Chain 2\n",
    "\n",
    "template = \"\"\"Given a meal, give a short and simple recipe on how to make that dish at home.\n",
    "% MEAL\n",
    "{user_meal}\n",
    "\n",
    "YOUR RESPONSE:\n",
    "\"\"\"\n",
    "prompt_template = PromptTemplate(input_variables=[\"user_meal\"], template=template)\n",
    "\n",
    "# Holds my 'meal' chain\n",
    "meal_chain = LLMChain(llm=llm, prompt=prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "7d8bcdf7-512b-48bc-86a5-12294a121944",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Now, we can connect them together via simpleSequentialPipeline\n",
    "\n",
    "overall_chain = SimpleSequentialChain(chains=[location_chain, meal_chain], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "eb7530b2-7b14-476f-9d86-08e645485afb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3mPad Thai. This classic Thai dish is made with rice noodles, eggs, garlic, chili, peanuts and a sweet-sour sauce and is widely popular in Bangkok.\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3m\n",
      "Ingredients:\n",
      "- 2 cups rice noodles\n",
      "- 2 eggs\n",
      "- 4 cloves garlic\n",
      "- 2 tbsp chili sauce\n",
      "- 1/4 cup chopped peanuts\n",
      "- 2 tbsp tamarind paste\n",
      "- 2 tbsp brown sugar\n",
      "- 2 tbsp fish sauce\n",
      "- 2 tbsp lime juice\n",
      "\n",
      "Instructions: \n",
      "\n",
      "1. Cook the rice noodles according to the package instructions.\n",
      "\n",
      "2. In a separate pan, scramble 2 eggs and add in the minced garlic.\n",
      "\n",
      "3. Mix in the chili sauce, peanuts, tamarind paste and brown sugar.\n",
      "\n",
      "4. Add the noodles to the pan and combine all the ingredients together.\n",
      "\n",
      "5. Finally, add the fish sauce and lime juice and stir fry until everything is evenly combined.\n",
      "\n",
      "6. Serve the Pad Thai hot and enjoy!\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "review = overall_chain.run(\"Bangkok\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e0972f-245b-4648-85f2-fefcfd775113",
   "metadata": {},
   "source": [
    "# 7. Agents\n",
    "\n",
    "- Sometimes the user query is so random, and predetermined chain is not flexible enough\n",
    "- Agents is smart enough to figure out create their own chain, so you don't have to predetermined chain\n",
    "- They can decided the tool, or source to use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38093dc-3121-4dfb-9235-04792cdb99a7",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Agent Case 1 : Serpapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "994cfc24-eb9d-442d-a6a5-499d22a2d64b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.agents import load_tools\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "ca9f2578-2c6f-45af-999a-ecd1511c1f0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "llm = OpenAI(temperature=0)\n",
    "toolkit = load_tools([\"serpapi\"], llm=llm)\n",
    "agent = initialize_agent(toolkit, llm, agent=\"zero-shot-react-description\", verbose=True, return_intermediate_steps=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "d2d812b7-7095-4101-bebd-3326663c5170",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I should try to find out what band Natalie Bergman is a part of.\n",
      "Action: Search\n",
      "Action Input: \"Natalie Bergman band\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mNatalie Bergman is an American singer-songwriter. She is one half of the duo Wild Belle, along with her brother Elliot Bergman. Her debut solo album, Mercy, was released on Third Man Records on May 7, 2021. She is based in Los Angeles.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should search for the debut album of Wild Belle.\n",
      "Action: Search\n",
      "Action Input: \"Wild Belle debut album\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mIsles\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
      "Final Answer: Isles is the debut album of Wild Belle, the band that Natalie Bergman is a part of.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "[\n",
      "  [\n",
      "    [\n",
      "      \"Search\",\n",
      "      \"Natalie Bergman band\",\n",
      "      \" I should try to find out what band Natalie Bergman is a part of.\\nAction: Search\\nAction Input: \\\"Natalie Bergman band\\\"\"\n",
      "    ],\n",
      "    \"Natalie Bergman is an American singer-songwriter. She is one half of the duo Wild Belle, along with her brother Elliot Bergman. Her debut solo album, Mercy, was released on Third Man Records on May 7, 2021. She is based in Los Angeles.\"\n",
      "  ],\n",
      "  [\n",
      "    [\n",
      "      \"Search\",\n",
      "      \"Wild Belle debut album\",\n",
      "      \" I should search for the debut album of Wild Belle.\\nAction: Search\\nAction Input: \\\"Wild Belle debut album\\\"\"\n",
      "    ],\n",
      "    \"Isles\"\n",
      "  ]\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "response = agent({\"input\":\"what was the first album of the\" \n",
    "                    \"band that Natalie Bergman is a part of?\"})\n",
    "\n",
    "print(json.dumps(response[\"intermediate_steps\"], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100931ca-feac-41ea-8c56-75562a0e2442",
   "metadata": {},
   "source": [
    "### Agent Case 2 : PdfIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f95bca-fe66-4281-a6ca-b2217cb6a71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS \n",
    "\n",
    "# Size is count by character not token\n",
    "def initialize_db(document_path):\n",
    "    # Declare toolset\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000,chunk_overlap=50)\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    \n",
    "    # Run\n",
    "    loader = PyPDFLoader(document_path)\n",
    "    texts = text_splitter.split_documents(documents)\n",
    "\n",
    "    # Embed and store in this\n",
    "    db = FAISS.from_documents(texts,embeddings)\n",
    "    return db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "570a6746-049e-402d-b926-e79c88b1995d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "document_path = 'source/why_we_sleep.pdf'\n",
    "search_kwargss = {'k': 5}\n",
    "\n",
    "db = initialize_db(document_path)\n",
    "retriever = db.as_retriever(search_kwargs = search_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "e7c7e2de-4e04-4365-98a6-0abb84825135",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Appendix\\nTwelve Tips for Healthy SleepI\\n1.\\xa0Stick to a sleep schedule. Go to bed and wake up at the same time each\\nday. As creatures of habit, people have a hard time adjusting to changes in\\nsleep patterns. Sleeping later on weekends won’t fully make up for a lack\\nof sleep during the week and will make it harder to wake up early on\\nMonday morning. Set an alarm for bedtime. Often we set an alarm for\\nwhen it’s time to wake up but fail to do so for when it’s time to go to\\nsleep. If there is only one piece of advice you remember and take from\\nthese twelve tips, this should be it.\\n2.\\xa0Exercise is great, but not too late in the day. Try to exercise at least thirty\\nminutes on most days but not later than two to three hours before your\\nbedtime.\\n3.\\xa0Avoid caﬀeine and nicotine. Coﬀee, colas, certain teas, and chocolate\\ncontain the stimulant caﬀeine, and its eﬀects can take as long as eight\\nhours to wear oﬀ fully. \\ue033erefore, a cup of coﬀee in the late afternoon can', metadata={'source': 'source/why_we_sleep.pdf', 'page': 332}),\n",
       " Document(page_content='night to go. Moreover, few of us enjoy a full afternoon nap, further\\ncontributing to our state of sleep bankruptcy.\\n\\ue033e practice of biphasic sleep is not cultural in origin, however. It is deeply\\nbiological. All humans, irrespective of culture or geographical location, have a\\ngenetically hardwired dip in alertness that occurs in the midafternoon hours.\\nObserve any post-lunch meeting around a boardroom table and this fact will\\nbecome evidently clear. Like puppets whose control strings were let loose,\\nthen rapidly pulled taut, heads will start dipping then quickly snap back', metadata={'source': 'source/why_we_sleep.pdf', 'page': 71}),\n",
       " Document(page_content='they will place special focus on areas of the body that need the most help. In\\nthe same way, sleep spindles bathe all parts of the brain, but a\\ndisproportionate emphasis will be placed on those parts of the brain that\\nhave been worked hardest with learning during the day.\\nPerhaps more relevant to the modern world is the time-of-night eﬀect we\\ndiscovered. \\ue033ose last two hours of sleep are precisely the window that many\\nof us feel it is okay to cut short to get a jump start on the day. As a result, we\\nmiss out on this feast of late-morning sleep spindles. It also brings to mind\\nthe prototypical Olympic coach who stoically has her athletes practicing late\\ninto the day, only to have them wake in the early hours of the morning and\\nreturn to practice. In doing so, coaches may be innocently but eﬀectively\\ndenying an important phase of motor memory development within the brain\\n—one that ﬁne-tunes skilled athletic performance. When you consider that', metadata={'source': 'source/why_we_sleep.pdf', 'page': 124}),\n",
       " Document(page_content='very small performance diﬀerences often separate winning a gold medal\\nfrom a last-place ﬁnish in professional athletics, then any competitive\\nadvantage you can gain, such as that naturally oﬀered by sleep, can help\\ndetermine whether or not you will hear your national anthem echo around\\nthe stadium. Not without putting too ﬁne a point on it, if you don’t snooze,\\nyou lose.\\n\\ue033e 100-meter sprint superstar Usain Bolt has, on many occasions, taken\\nnaps in the hours before breaking the world record, and before Olympic\\nﬁnals in which he won gold. Our own studies support his wisdom: daytime', metadata={'source': 'source/why_we_sleep.pdf', 'page': 124}),\n",
       " Document(page_content='standard measure of sleep, estimated a range of 6 to 7.5 hours of this time\\nwas spent asleep. \\ue033e sleep opportunity that these tribespeople provide\\nthemselves is therefore almost identical to what the National Sleep\\nFoundation and the Centers for Disease Control and Prevention recommend\\nfor all adult humans: 7 to 9 hours of time in bed.', metadata={'source': 'source/why_we_sleep.pdf', 'page': 249})]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = 'which time we best sleep'\n",
    "retriever.get_relevant_documents(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "fc7d624f-3544-47cf-a52e-bb8bdeb549b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# There are 2 tools we allowed for this : LLM, Sleep_Database\n",
    "# 1. LLM for general logics \n",
    "# 2. For specialization database about sleep\n",
    "\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.tools import Tool\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate(input_variables = ['query'], template ='{query}')\n",
    "\n",
    "# Initialize tools (LLM + Sleep_Database)\n",
    "llm_chain = LLMChain(llm=llm,prompt=prompt)\n",
    "llm_tool = Tool(name=\"Language model\", func=llm_chain.run, description=\"Use this tool for general purpose queries and logics\")\n",
    "sleep_db_tool = Tool(name=\"Sleep Database\", func=retriever.get_relevant_documents, description = \"Use this tool when you want to search for the reference about sleeping\")\n",
    "\n",
    "tools = [llm_tool,sleep_db_tool]\n",
    "\n",
    "# Initialize agent\n",
    "zero_shot_agents = initialize_agent(agent='zero-shot-react-description',tools=tools,llm=llm,verbose=True,max_iterations=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "a2989ad9-6514-4f3e-8cb0-906fc520f0d8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to find out what the research says about sleeping\n",
      "Action: Sleep Database\n",
      "Action Input: Best time to sleep\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m[Document(page_content='standard measure of sleep, estimated a range of 6 to 7.5 hours of this time\\nwas spent asleep. \\ue033e sleep opportunity that these tribespeople provide\\nthemselves is therefore almost identical to what the National Sleep\\nFoundation and the Centers for Disease Control and Prevention recommend\\nfor all adult humans: 7 to 9 hours of time in bed.', metadata={'source': 'source/why_we_sleep.pdf', 'page': 249}), Document(page_content='Appendix\\nTwelve Tips for Healthy SleepI\\n1.\\xa0Stick to a sleep schedule. Go to bed and wake up at the same time each\\nday. As creatures of habit, people have a hard time adjusting to changes in\\nsleep patterns. Sleeping later on weekends won’t fully make up for a lack\\nof sleep during the week and will make it harder to wake up early on\\nMonday morning. Set an alarm for bedtime. Often we set an alarm for\\nwhen it’s time to wake up but fail to do so for when it’s time to go to\\nsleep. If there is only one piece of advice you remember and take from\\nthese twelve tips, this should be it.\\n2.\\xa0Exercise is great, but not too late in the day. Try to exercise at least thirty\\nminutes on most days but not later than two to three hours before your\\nbedtime.\\n3.\\xa0Avoid caﬀeine and nicotine. Coﬀee, colas, certain teas, and chocolate\\ncontain the stimulant caﬀeine, and its eﬀects can take as long as eight\\nhours to wear oﬀ fully. \\ue033erefore, a cup of coﬀee in the late afternoon can', metadata={'source': 'source/why_we_sleep.pdf', 'page': 332}), Document(page_content='PART 2\\nWhy Should You Sleep?', metadata={'source': 'source/why_we_sleep.pdf', 'page': 104}), Document(page_content='right before bed. Body temperature can remain high for an hour or two after\\nphysical exertion. Should this occur too close to bedtime, it can be diﬃcult to\\ndrop your core temperature suﬃciently to initiate sleep due to the exercise-\\ndriven increase in metabolic rate. Best to get your workout in at least two to\\nthree hours before turning the bedside light out (none LED-powered, I trust).\\nWhen it comes to diet, there is limited research investigating how the\\nfoods you eat, and the pattern of eating, impact your sleep at night. Severe\\ncaloric restriction, such as reducing food intake to just 800 calories a day for\\none month, makes it harder to fall asleep normally, and decreases the\\namount of deep NREM sleep at night.\\nWhat you eat also appears to have some impact on your nighttime sleep.\\nEating a high-carbohydrate, low-fat diet for two days decreases the amount\\nof deep NREM sleep at night, but increases the amount of REM sleep', metadata={'source': 'source/why_we_sleep.pdf', 'page': 282}), Document(page_content='very small performance diﬀerences often separate winning a gold medal\\nfrom a last-place ﬁnish in professional athletics, then any competitive\\nadvantage you can gain, such as that naturally oﬀered by sleep, can help\\ndetermine whether or not you will hear your national anthem echo around\\nthe stadium. Not without putting too ﬁne a point on it, if you don’t snooze,\\nyou lose.\\n\\ue033e 100-meter sprint superstar Usain Bolt has, on many occasions, taken\\nnaps in the hours before breaking the world record, and before Olympic\\nﬁnals in which he won gold. Our own studies support his wisdom: daytime', metadata={'source': 'source/why_we_sleep.pdf', 'page': 124})]\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to look through the documents to find the answer\n",
      "Action: Language model\n",
      "Action Input: What is the best time to sleep\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m\n",
      "\n",
      "The best time to sleep is between 7-9 hours before your usual wake-up time. This will help ensure that you get enough restful sleep and wake up feeling refreshed.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: The best time to sleep is between 7-9 hours before your usual wake-up time.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Which time is best to sleep',\n",
       " 'output': 'The best time to sleep is between 7-9 hours before your usual wake-up time.'}"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_shot_agents(\"Which time is best to sleep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "9c9b4a76-fdf5-4222-b028-de0a58124770",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "# Declare memory for it, it will lookup for variable chat_history when needed (error if not chat_history)\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
    "\n",
    "# This is what we expected, but would be better if we do conversational instead\n",
    "conversational_agents = initialize_agent(agent='conversational-react-description',\n",
    "                                         tools=tools,llm=llm,\n",
    "                                         memory = memory,\n",
    "                                         verbose=True,\n",
    "                                         max_iterations=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "0f04ff71-f6ac-426f-8384-84a38e10acc4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Thought: Do I need to use a tool? Yes\n",
      "Action: Sleep Database\n",
      "Action Input: best time to sleep\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m[Document(page_content='Appendix\\nTwelve Tips for Healthy SleepI\\n1.\\xa0Stick to a sleep schedule. Go to bed and wake up at the same time each\\nday. As creatures of habit, people have a hard time adjusting to changes in\\nsleep patterns. Sleeping later on weekends won’t fully make up for a lack\\nof sleep during the week and will make it harder to wake up early on\\nMonday morning. Set an alarm for bedtime. Often we set an alarm for\\nwhen it’s time to wake up but fail to do so for when it’s time to go to\\nsleep. If there is only one piece of advice you remember and take from\\nthese twelve tips, this should be it.\\n2.\\xa0Exercise is great, but not too late in the day. Try to exercise at least thirty\\nminutes on most days but not later than two to three hours before your\\nbedtime.\\n3.\\xa0Avoid caﬀeine and nicotine. Coﬀee, colas, certain teas, and chocolate\\ncontain the stimulant caﬀeine, and its eﬀects can take as long as eight\\nhours to wear oﬀ fully. \\ue033erefore, a cup of coﬀee in the late afternoon can', metadata={'source': 'source/why_we_sleep.pdf', 'page': 332}), Document(page_content='standard measure of sleep, estimated a range of 6 to 7.5 hours of this time\\nwas spent asleep. \\ue033e sleep opportunity that these tribespeople provide\\nthemselves is therefore almost identical to what the National Sleep\\nFoundation and the Centers for Disease Control and Prevention recommend\\nfor all adult humans: 7 to 9 hours of time in bed.', metadata={'source': 'source/why_we_sleep.pdf', 'page': 249}), Document(page_content='right before bed. Body temperature can remain high for an hour or two after\\nphysical exertion. Should this occur too close to bedtime, it can be diﬃcult to\\ndrop your core temperature suﬃciently to initiate sleep due to the exercise-\\ndriven increase in metabolic rate. Best to get your workout in at least two to\\nthree hours before turning the bedside light out (none LED-powered, I trust).\\nWhen it comes to diet, there is limited research investigating how the\\nfoods you eat, and the pattern of eating, impact your sleep at night. Severe\\ncaloric restriction, such as reducing food intake to just 800 calories a day for\\none month, makes it harder to fall asleep normally, and decreases the\\namount of deep NREM sleep at night.\\nWhat you eat also appears to have some impact on your nighttime sleep.\\nEating a high-carbohydrate, low-fat diet for two days decreases the amount\\nof deep NREM sleep at night, but increases the amount of REM sleep', metadata={'source': 'source/why_we_sleep.pdf', 'page': 282}), Document(page_content='very small performance diﬀerences often separate winning a gold medal\\nfrom a last-place ﬁnish in professional athletics, then any competitive\\nadvantage you can gain, such as that naturally oﬀered by sleep, can help\\ndetermine whether or not you will hear your national anthem echo around\\nthe stadium. Not without putting too ﬁne a point on it, if you don’t snooze,\\nyou lose.\\n\\ue033e 100-meter sprint superstar Usain Bolt has, on many occasions, taken\\nnaps in the hours before breaking the world record, and before Olympic\\nﬁnals in which he won gold. Our own studies support his wisdom: daytime', metadata={'source': 'source/why_we_sleep.pdf', 'page': 124}), Document(page_content='asleep, you should get an hour of exposure to morning sunlight and turn\\ndown the lights before bedtime.\\n12.\\xa0Don’t lie in bed awake. If you ﬁnd yourself still awake after staying in bed\\nfor more than twenty minutes or if you are starting to feel anxious or\\nworried, get up and do some relaxing activity until you feel sleepy. \\ue033e\\nanxiety of not being able to sleep can make it harder to fall asleep.', metadata={'source': 'source/why_we_sleep.pdf', 'page': 333})]\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m Do I need to use a tool? No\n",
      "AI: According to the National Sleep Foundation and the Centers for Disease Control and Prevention, adults should get 7 to 9 hours of sleep each night. It is best to stick to a regular sleep schedule and avoid caffeine and nicotine before bed. Exercise should be done at least 30 minutes before bed, and it is important to get an hour of exposure to morning sunlight and turn down the lights before bedtime.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'what is the best time we should sleep',\n",
       " 'chat_history': '',\n",
       " 'output': 'According to the National Sleep Foundation and the Centers for Disease Control and Prevention, adults should get 7 to 9 hours of sleep each night. It is best to stick to a regular sleep schedule and avoid caffeine and nicotine before bed. Exercise should be done at least 30 minutes before bed, and it is important to get an hour of exposure to morning sunlight and turn down the lights before bedtime.'}"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversational_agents(\"what is the best time we should sleep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "357ae594-960d-4b32-8df0-34579c5d04ac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Thought: Do I need to use a tool? No\n",
      "AI: Seven to nine hours of sleep is recommended because it is the amount of time needed for the body to go through all of the stages of sleep, including deep sleep and REM sleep. Deep sleep helps to restore the body and mind, while REM sleep helps to consolidate memories and process emotions. Getting enough sleep is important for physical and mental health, and can help to improve concentration, mood, and overall wellbeing.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Why 7-9 hours is the best ?',\n",
       " 'chat_history': 'Human: what is the best time we should sleep\\nAI: According to the National Sleep Foundation and the Centers for Disease Control and Prevention, adults should get 7 to 9 hours of sleep each night. It is best to stick to a regular sleep schedule and avoid caffeine and nicotine before bed. Exercise should be done at least 30 minutes before bed, and it is important to get an hour of exposure to morning sunlight and turn down the lights before bedtime.',\n",
       " 'output': 'Seven to nine hours of sleep is recommended because it is the amount of time needed for the body to go through all of the stages of sleep, including deep sleep and REM sleep. Deep sleep helps to restore the body and mind, while REM sleep helps to consolidate memories and process emotions. Getting enough sleep is important for physical and mental health, and can help to improve concentration, mood, and overall wellbeing.'}"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversational_agents(\"Why 7-9 hours is the best ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "79cd312b-d8ad-40d0-9220-0453886e419f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Thought: Do I need to use a tool? Yes\n",
      "Action: Sleep Database\n",
      "Action Input: Why 7-9 hours is the best?\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m[Document(page_content='beings do not, after all, need a full eight hours of sleep, some suggesting we\\ncan survive just ﬁne on six hours or less. For example, the headline of one\\nprominent US newspaper read:\\n“Sleep Study on Modern-Day Hunter-Gatherers Dispels Notion \\ue033at We’re\\nWired to Need 8 Hours a Day.”\\nOthers started out with the already incorrect assumption that modern\\nsocieties need only seven hours of sleep, and then questioned whether we\\neven need that much: “Do We Really Need to Sleep 7 Hours a Night?”\\nHow can such prestigious and well-respected entities reach these\\nconclusions, especially after the science that I have presented in this\\nchapter? Let us carefully reevaluate the ﬁndings, and see if we still arrive at\\nthe same conclusion.\\nFirst, when you read the paper, you will learn that the tribespeople were\\nactually giving themselves a 7- to 8.5-hour sleep opportunity each night.\\nMoreover, the wristwatch device, which is neither a precise nor gold', metadata={'source': 'source/why_we_sleep.pdf', 'page': 249}), Document(page_content='standard measure of sleep, estimated a range of 6 to 7.5 hours of this time\\nwas spent asleep. \\ue033e sleep opportunity that these tribespeople provide\\nthemselves is therefore almost identical to what the National Sleep\\nFoundation and the Centers for Disease Control and Prevention recommend\\nfor all adult humans: 7 to 9 hours of time in bed.', metadata={'source': 'source/why_we_sleep.pdf', 'page': 249}), Document(page_content='an eight-and-a-half-hour sleep opportunity each night for ﬁve nights,\\nrecorded with electrodes placed on your head. In the other arm of the study,\\nyou are only allowed four to ﬁve hours of sleep for ﬁve nights, also measured\\nwith electrode recordings. In both study arms, you will receive exactly the\\nsame amount and type of food, and your degree of physical activity is also\\nheld constant. Each day, your sense of hunger and food intake are monitored,\\nas are your circulating levels of leptin and ghrelin.\\nUsing precisely this experimental design in a group of healthy, lean\\nparticipants, Van Cauter discovered that individuals were far more ravenous\\nwhen sleeping four to ﬁve hours a night. \\ue033is despite being given the same\\namount of food and being similarly active, which kept the hunger levels of\\nthese same individuals under calm control when they were getting eight or\\nmore hours of sleep. \\ue033e strong rise of hunger pangs and increased reported', metadata={'source': 'source/why_we_sleep.pdf', 'page': 168}), Document(page_content='synergistic and critical, though often diﬀerent, survival advantages. \\ue033ere is\\nan adaptive balance to be struck between wakefulness and sleep. In humans,\\nthat appears to be around sixteen hours of total wakefulness, and around\\neight hours of total sleep, for an average adult.\\nI.\\xa0https://sleepfoundation.org.', metadata={'source': 'source/why_we_sleep.pdf', 'page': 252}), Document(page_content='long stretches. \\ue033ey spend much of their waking lives in pursuit and\\npreparation of nutrition. For example, the Hadza will face days where they\\nobtain 1,400 calories or less, and routinely eat 300 to 600 fewer daily calories\\nthan those of us in modern Western cultures. A large proportion of their year\\nis therefore spent in a state of lower-level starvation, one that can trigger\\nwell-characterized biological pathways that reduce sleep time, even though\\nsleep need remains higher than that obtained if food were abundant.\\nConcluding that humans, modern-living or pre-industrial, need less than\\nseven hours of sleep therefore appears to be a wishful conceit, and a tabloid\\nmyth.\\nIS SLEEPING NINE H OUR S A NIGHT TOO MUCH?\\nEpidemiological evidence suggests that the relationship between sleep and\\nmortality risk is not linear, such that the more and more sleep you get, the\\nlower and lower your death risk (and vice versa). Rather, there is an upward', metadata={'source': 'source/why_we_sleep.pdf', 'page': 251})]\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m Do I need to use a tool? No\n",
      "AI: Seven to nine hours of sleep is recommended because it is the amount of time needed for the body to go through all of the stages of sleep, including deep sleep and REM sleep. Deep sleep helps to restore the body and mind, while REM sleep helps to consolidate memories and process emotions. Getting enough sleep is important for physical and mental health, and can help to improve concentration, mood, and overall wellbeing.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Why 7-9 hours is the best ? Please use sleep database tool',\n",
       " 'chat_history': 'Human: what is the best time we should sleep\\nAI: According to the National Sleep Foundation and the Centers for Disease Control and Prevention, adults should get 7 to 9 hours of sleep each night. It is best to stick to a regular sleep schedule and avoid caffeine and nicotine before bed. Exercise should be done at least 30 minutes before bed, and it is important to get an hour of exposure to morning sunlight and turn down the lights before bedtime.\\nHuman: Why 7-9 hours is the best ?\\nAI: Seven to nine hours of sleep is recommended because it is the amount of time needed for the body to go through all of the stages of sleep, including deep sleep and REM sleep. Deep sleep helps to restore the body and mind, while REM sleep helps to consolidate memories and process emotions. Getting enough sleep is important for physical and mental health, and can help to improve concentration, mood, and overall wellbeing.',\n",
       " 'output': 'Seven to nine hours of sleep is recommended because it is the amount of time needed for the body to go through all of the stages of sleep, including deep sleep and REM sleep. Deep sleep helps to restore the body and mind, while REM sleep helps to consolidate memories and process emotions. Getting enough sleep is important for physical and mental health, and can help to improve concentration, mood, and overall wellbeing.'}"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversational_agents(\"Why 7-9 hours is the best ? Please use sleep database tool\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:oic_langchain]",
   "language": "python",
   "name": "conda-env-oic_langchain-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
